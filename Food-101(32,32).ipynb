{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f6752e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6efb0411",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the Food101 dataset with 'train' split\n",
    "(ds_train, ds_test) = tfds.load('food101', split='train', as_supervised=True, with_info=True)\n",
    "\n",
    "# You can also load the 'validation' split if needed\n",
    "# (ds_validation, _) = tfds.load('food101', split='validation', as_supervised=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "424fd640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images shape: (64, 32, 32, 3)\n",
      "Labels shape: (64, 101)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define a function to resize images\n",
    "def resize_image(image, label):\n",
    "    image = tf.image.resize(image, (32, 32))\n",
    "    return image, label\n",
    "\n",
    "# Apply resizing to the training dataset\n",
    "ds_train = ds_train.map(resize_image)\n",
    "\n",
    "# Normalize pixel values to be in the range [0, 1]\n",
    "ds_train = ds_train.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "\n",
    "# Shuffle and batch the training dataset\n",
    "ds_train = ds_train.shuffle(10000).batch(64)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "def categorical_labels(images, labels):\n",
    "    return images, tf.one_hot(labels, depth=101)  # 101 classes in Food101 dataset\n",
    "\n",
    "ds_train = ds_train.map(categorical_labels)\n",
    "\n",
    "# Verify the shapes\n",
    "for images, labels in ds_train.take(1):\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91a129e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 1s 0us/step\n",
      "94781440/94765736 [==============================] - 1s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(101, activation='softmax'))  # 101 classes in Food101 dataset\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7fa017e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "1184/1184 [==============================] - 2428s 2s/step - loss: 4.9420 - accuracy: 0.0173\n",
      "Epoch 2/50\n",
      "1184/1184 [==============================] - 2285s 2s/step - loss: 4.3828 - accuracy: 0.0418\n",
      "Epoch 3/50\n",
      "1184/1184 [==============================] - 2289s 2s/step - loss: 4.1092 - accuracy: 0.0777\n",
      "Epoch 4/50\n",
      "1184/1184 [==============================] - 2293s 2s/step - loss: 3.8758 - accuracy: 0.1131\n",
      "Epoch 5/50\n",
      "1184/1184 [==============================] - 2302s 2s/step - loss: 3.6562 - accuracy: 0.1465\n",
      "Epoch 6/50\n",
      "1184/1184 [==============================] - 2297s 2s/step - loss: 3.4824 - accuracy: 0.1768\n",
      "Epoch 7/50\n",
      "1184/1184 [==============================] - 2293s 2s/step - loss: 3.3330 - accuracy: 0.2013\n",
      "Epoch 8/50\n",
      "1184/1184 [==============================] - 2297s 2s/step - loss: 3.1869 - accuracy: 0.2261\n",
      "Epoch 9/50\n",
      "1184/1184 [==============================] - 2298s 2s/step - loss: 3.0452 - accuracy: 0.2538\n",
      "Epoch 10/50\n",
      "1184/1184 [==============================] - 2305s 2s/step - loss: 2.8904 - accuracy: 0.2815\n",
      "Epoch 11/50\n",
      "1184/1184 [==============================] - 2294s 2s/step - loss: 2.7192 - accuracy: 0.3120\n",
      "Epoch 12/50\n",
      "1184/1184 [==============================] - 2348s 2s/step - loss: 2.5439 - accuracy: 0.3455\n",
      "Epoch 13/50\n",
      "1184/1184 [==============================] - 2304s 2s/step - loss: 2.3508 - accuracy: 0.3845\n",
      "Epoch 14/50\n",
      "1184/1184 [==============================] - 2307s 2s/step - loss: 2.1678 - accuracy: 0.4229\n",
      "Epoch 15/50\n",
      "1184/1184 [==============================] - 2310s 2s/step - loss: 1.9694 - accuracy: 0.4634\n",
      "Epoch 16/50\n",
      "1184/1184 [==============================] - 2313s 2s/step - loss: 1.7854 - accuracy: 0.5078\n",
      "Epoch 17/50\n",
      "1184/1184 [==============================] - 2314s 2s/step - loss: 1.6009 - accuracy: 0.5490\n",
      "Epoch 18/50\n",
      "1184/1184 [==============================] - 2309s 2s/step - loss: 1.4328 - accuracy: 0.5888\n",
      "Epoch 19/50\n",
      "1184/1184 [==============================] - 2329s 2s/step - loss: 1.2844 - accuracy: 0.6256\n",
      "Epoch 20/50\n",
      "1184/1184 [==============================] - 2308s 2s/step - loss: 1.1344 - accuracy: 0.6643\n",
      "Epoch 21/50\n",
      "1184/1184 [==============================] - 2322s 2s/step - loss: 1.0157 - accuracy: 0.6957\n",
      "Epoch 22/50\n",
      "1184/1184 [==============================] - 2301s 2s/step - loss: 0.9164 - accuracy: 0.7211\n",
      "Epoch 23/50\n",
      "1184/1184 [==============================] - 2305s 2s/step - loss: 0.8196 - accuracy: 0.7505\n",
      "Epoch 24/50\n",
      "1184/1184 [==============================] - 2300s 2s/step - loss: 0.7421 - accuracy: 0.7706\n",
      "Epoch 25/50\n",
      "1184/1184 [==============================] - 2299s 2s/step - loss: 0.6712 - accuracy: 0.7910\n",
      "Epoch 26/50\n",
      "1184/1184 [==============================] - 2310s 2s/step - loss: 0.6220 - accuracy: 0.8057\n",
      "Epoch 27/50\n",
      "1184/1184 [==============================] - 2303s 2s/step - loss: 0.5751 - accuracy: 0.8183\n",
      "Epoch 28/50\n",
      "1184/1184 [==============================] - 2303s 2s/step - loss: 0.5394 - accuracy: 0.8281\n",
      "Epoch 29/50\n",
      "1184/1184 [==============================] - 2317s 2s/step - loss: 0.4976 - accuracy: 0.8423\n",
      "Epoch 30/50\n",
      "1184/1184 [==============================] - 2304s 2s/step - loss: 0.4611 - accuracy: 0.8518\n",
      "Epoch 31/50\n",
      "1184/1184 [==============================] - 2731s 2s/step - loss: 0.4457 - accuracy: 0.8593\n",
      "Epoch 32/50\n",
      "1184/1184 [==============================] - 4365s 4s/step - loss: 0.4212 - accuracy: 0.8660\n",
      "Epoch 33/50\n",
      "1184/1184 [==============================] - 4263s 4s/step - loss: 0.4049 - accuracy: 0.8700\n",
      "Epoch 34/50\n",
      "1184/1184 [==============================] - 4661s 4s/step - loss: 0.3848 - accuracy: 0.8781\n",
      "Epoch 35/50\n",
      "1184/1184 [==============================] - 4721s 4s/step - loss: 0.3637 - accuracy: 0.8846\n",
      "Epoch 36/50\n",
      "1184/1184 [==============================] - 4507s 4s/step - loss: 0.3540 - accuracy: 0.8878\n",
      "Epoch 37/50\n",
      "1184/1184 [==============================] - 4552s 4s/step - loss: 0.3425 - accuracy: 0.8922\n",
      "Epoch 38/50\n",
      "1184/1184 [==============================] - 4979s 4s/step - loss: 0.3269 - accuracy: 0.8962\n",
      "Epoch 39/50\n",
      "1184/1184 [==============================] - 3290s 3s/step - loss: 0.3102 - accuracy: 0.9009\n",
      "Epoch 40/50\n",
      "1184/1184 [==============================] - 3314s 3s/step - loss: 0.2941 - accuracy: 0.9080\n",
      "Epoch 41/50\n",
      "1184/1184 [==============================] - 3399s 3s/step - loss: 0.2970 - accuracy: 0.9056\n",
      "Epoch 42/50\n",
      "1184/1184 [==============================] - 3505s 3s/step - loss: 0.2828 - accuracy: 0.9102\n",
      "Epoch 43/50\n",
      "1184/1184 [==============================] - 3521s 3s/step - loss: 0.2807 - accuracy: 0.9105\n",
      "Epoch 44/50\n",
      "1184/1184 [==============================] - 3618s 3s/step - loss: 0.2692 - accuracy: 0.9133\n",
      "Epoch 45/50\n",
      "1184/1184 [==============================] - 3650s 3s/step - loss: 0.2621 - accuracy: 0.9162\n",
      "Epoch 46/50\n",
      "1184/1184 [==============================] - 3726s 3s/step - loss: 0.2564 - accuracy: 0.9193\n",
      "Epoch 47/50\n",
      "1184/1184 [==============================] - 3692s 3s/step - loss: 0.2504 - accuracy: 0.9202\n",
      "Epoch 48/50\n",
      "1184/1184 [==============================] - 3693s 3s/step - loss: 0.2377 - accuracy: 0.9240\n",
      "Epoch 49/50\n",
      "1184/1184 [==============================] - 3701s 3s/step - loss: 0.2315 - accuracy: 0.9250\n",
      "Epoch 50/50\n",
      "1184/1184 [==============================] - 4076s 3s/step - loss: 0.2568 - accuracy: 0.9201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2b1e5a447f0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f244b498",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DatasetInfo' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-708e96f42de2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Apply preprocessing to the test dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[0mds_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocess_test_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# Create a list to store true labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DatasetInfo' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Define a function to resize and normalize test images\n",
    "def preprocess_test_image(image, label):\n",
    "    image = tf.image.resize(image, (32, 32))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    return image, label\n",
    "\n",
    "# Apply preprocessing to the test dataset\n",
    "ds_test = ds_test.map(preprocess_test_image)\n",
    "\n",
    "# Create a list to store true labels\n",
    "true_labels = []\n",
    "\n",
    "# Create a list to store predicted labels\n",
    "predicted_labels = []\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "for image, label in ds_test:\n",
    "    image = np.expand_dims(image, axis=0)  # Add a batch dimension\n",
    "    prediction = model.predict(image)\n",
    "    predicted_label = np.argmax(prediction, axis=1)\n",
    "    \n",
    "    true_labels.append(label.numpy())\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert lists to arrays for evaluation\n",
    "true_labels = np.concatenate(true_labels)\n",
    "predicted_labels = np.concatenate(predicted_labels)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7b29618",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'tensorflow_datasets.core.dataset_info.DatasetInfo'>, <class 'NoneType'>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-8749ee4a5190>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Make predictions on the test dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mds_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# Convert one-hot encoded predictions back to class labels\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1718\u001b[0m                         '. Consider setting it to AutoShardPolicy.DATA.')\n\u001b[0;32m   1719\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1720\u001b[1;33m       data_handler = data_adapter.get_data_handler(\n\u001b[0m\u001b[0;32m   1721\u001b[0m           \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1722\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mget_data_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1381\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"model\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"_cluster_coordinator\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_ClusterCoordinatorDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1383\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mDataHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution, distribute)\u001b[0m\n\u001b[0;32m   1135\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msteps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1137\u001b[1;33m     \u001b[0madapter_cls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1138\u001b[0m     self._adapter = adapter_cls(\n\u001b[0;32m   1139\u001b[0m         \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    974\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0madapter_cls\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    975\u001b[0m     \u001b[1;31m# TODO(scottzhu): This should be a less implementation-specific error.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 976\u001b[1;33m     raise ValueError(\n\u001b[0m\u001b[0;32m    977\u001b[0m         \u001b[1;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    978\u001b[0m         \"input: {}, {}\".format(\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'tensorflow_datasets.core.dataset_info.DatasetInfo'>, <class 'NoneType'>"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(ds_test)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Manually generate ground truth labels for evaluation\n",
    "true_labels = []\n",
    "for _, label in ds_test:\n",
    "    true_labels.extend(label.numpy())\n",
    "\n",
    "true_labels = np.argmax(true_labels, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Assuming you have test_loss and test_accuracy available\n",
    "# If not, you'll need to calculate them based on your model and test dataset\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925df83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f9447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d19d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606146b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ba2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efd4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287aff3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68d10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2851ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43165ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09e57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6ead7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
