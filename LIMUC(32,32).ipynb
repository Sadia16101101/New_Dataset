{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "129339f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (9590, 32, 32, 3)\n",
      "Shape of Y_train_categorical: (9590, 5)\n",
      "Shape of X_test: (1686, 32, 32, 3)\n",
      "Shape of Y_test_categorical: (1686, 5)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Define the paths to your dataset folders\n",
    "train_dataset_dir = \"/Users/sadianasrintisha/Desktop/Dataset/Ulcerative Colitis (LIMUC) Dataset/train_and_validation_sets\"\n",
    "test_dataset_dir = \"/Users/sadianasrintisha/Desktop/Dataset/Ulcerative Colitis (LIMUC) Dataset/test_set\"\n",
    "\n",
    "# Initialize empty lists for X_train, Y_train, X_test, and Y_test\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []\n",
    "\n",
    "# Initialize an empty list to store categorical labels\n",
    "categorical_labels = []\n",
    "\n",
    "# Define a function to read and preprocess images\n",
    "def process_images(folder_path, label, is_train_set=True):\n",
    "    for filename in os.listdir(folder_path):\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        if os.path.isfile(file_path) and filename.endswith(\".bmp\"):  # Check if it's a file and ends with .bmp\n",
    "            # Open and resize the image to (32, 32, 3)\n",
    "            img = Image.open(file_path)\n",
    "            img = img.resize((32, 32))\n",
    "            img = img.convert(\"RGB\")\n",
    "            \n",
    "            # Convert image data to a NumPy array\n",
    "            img_array = np.array(img).astype('float32')  # Convert to float\n",
    "            \n",
    "            # Normalize the image data (optional)\n",
    "            img_array /= 255.0  # Normalize pixel values to [0, 1]\n",
    "            \n",
    "            # Append the image data to the appropriate list\n",
    "            if is_train_set:\n",
    "                X_train.append(img_array)\n",
    "                Y_train.append(label)  # Append the numerical label\n",
    "            else:\n",
    "                X_test.append(img_array)\n",
    "                Y_test.append(label)  # Append the numerical label\n",
    "            \n",
    "            # Append the label for categorical encoding\n",
    "            categorical_labels.append(label)  # Append the numerical label\n",
    "\n",
    "# List the folders inside the training dataset directory\n",
    "train_folders = os.listdir(train_dataset_dir)\n",
    "\n",
    "# Create a label encoder for categorical labels\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Loop through the training folders and process images\n",
    "for label, folder_name in enumerate(train_folders):\n",
    "    folder_path = os.path.join(train_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label)\n",
    "\n",
    "# List the folders inside the test dataset directory\n",
    "test_folders = os.listdir(test_dataset_dir)\n",
    "\n",
    "# Loop through the test folders and process images\n",
    "for label, folder_name in enumerate(test_folders):\n",
    "    folder_path = os.path.join(test_dataset_dir, folder_name)\n",
    "    if os.path.isdir(folder_path):  # Check if it's a directory\n",
    "        process_images(folder_path, label, is_train_set=False)\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "# Encode Y_train and Y_test categorically\n",
    "num_classes = len(np.unique(categorical_labels))\n",
    "  # Update this to match the number of classes\n",
    "\n",
    "# Convert Y_train and Y_test to NumPy arrays\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "# Make sure your labels are integers ranging from 0 to num_classes - 1\n",
    "Y_train = Y_train.astype(int)\n",
    "Y_test = Y_test.astype(int)\n",
    "\n",
    "# One-hot encode the labels\n",
    "Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "Y_test_categorical = to_categorical(Y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "\n",
    "# # Encode Y_train and Y_test categorically using the label encoder\n",
    "# num_classes = len(np.unique(Y_train))  # Automatically determine the number of classes\n",
    "# Y_train_categorical = to_categorical(Y_train, num_classes=num_classes)\n",
    "# Y_test_categorical = to_categorical(Y_test, num_classes=num_classes)\n",
    "\n",
    "\n",
    "# Check the shape of X_train, Y_train_categorical, X_test, and Y_test_categorical\n",
    "print(\"Shape of X_train:\", np.shape(X_train))\n",
    "print(\"Shape of Y_train_categorical:\", np.shape(Y_train_categorical))\n",
    "print(\"Shape of X_test:\", np.shape(X_test))\n",
    "print(\"Shape of Y_test_categorical:\", np.shape(Y_test_categorical))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d72ef55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers.legacy import Adam as LegacyAdam\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Change units to match the number of classes\n",
    "optimizer = LegacyAdam(learning_rate=0.001)\n",
    "\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Split your data into training and validation sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_valid, Y_train_categorical, Y_valid_categorical = train_test_split(\n",
    "    X_train, Y_train_categorical, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Create tf.data.Dataset for training and validation data\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train_categorical))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid, Y_valid_categorical))\n",
    "\n",
    "# Define batch size and shuffle the datasets\n",
    "batch_size = 64\n",
    "train_dataset = train_dataset.shuffle(buffer_size=len(X_train)).batch(batch_size)\n",
    "valid_dataset = valid_dataset.batch(batch_size)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7cfd9577",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "96/96 [==============================] - 206s 2s/step - loss: 1.1799 - accuracy: 0.5716 - val_loss: 84.6417 - val_accuracy: 0.5296\n",
      "Epoch 2/50\n",
      "96/96 [==============================] - 194s 2s/step - loss: 0.9017 - accuracy: 0.6414 - val_loss: 20.2841 - val_accuracy: 0.2847\n",
      "Epoch 3/50\n",
      "96/96 [==============================] - 198s 2s/step - loss: 0.8021 - accuracy: 0.6627 - val_loss: 20.4075 - val_accuracy: 0.5296\n",
      "Epoch 4/50\n",
      "96/96 [==============================] - 192s 2s/step - loss: 0.7873 - accuracy: 0.6824 - val_loss: 22.0330 - val_accuracy: 0.5296\n",
      "Epoch 5/50\n",
      "96/96 [==============================] - 189s 2s/step - loss: 0.7575 - accuracy: 0.6860 - val_loss: 1.6551 - val_accuracy: 0.5296\n",
      "Epoch 6/50\n",
      "96/96 [==============================] - 188s 2s/step - loss: 0.7022 - accuracy: 0.7064 - val_loss: 2.2022 - val_accuracy: 0.5296\n",
      "Epoch 7/50\n",
      "96/96 [==============================] - 196s 2s/step - loss: 0.8375 - accuracy: 0.6749 - val_loss: 2.4782 - val_accuracy: 0.5296\n",
      "Epoch 8/50\n",
      "96/96 [==============================] - 180s 2s/step - loss: 0.9429 - accuracy: 0.6277 - val_loss: 1.6200 - val_accuracy: 0.5394\n",
      "Epoch 9/50\n",
      "96/96 [==============================] - 179s 2s/step - loss: 0.9425 - accuracy: 0.6495 - val_loss: 21.3824 - val_accuracy: 0.5309\n",
      "Epoch 10/50\n",
      "96/96 [==============================] - 150s 2s/step - loss: 0.8461 - accuracy: 0.6552 - val_loss: 1.3554 - val_accuracy: 0.5577\n",
      "Epoch 11/50\n",
      "96/96 [==============================] - 133s 1s/step - loss: 0.8100 - accuracy: 0.6638 - val_loss: 1.7599 - val_accuracy: 0.5362\n",
      "Epoch 12/50\n",
      "96/96 [==============================] - 141s 1s/step - loss: 0.8079 - accuracy: 0.6792 - val_loss: 24.4736 - val_accuracy: 0.5453\n",
      "Epoch 13/50\n",
      "96/96 [==============================] - 143s 1s/step - loss: 0.8624 - accuracy: 0.6792 - val_loss: 2.2544 - val_accuracy: 0.4182\n",
      "Epoch 14/50\n",
      "96/96 [==============================] - 141s 1s/step - loss: 0.7922 - accuracy: 0.6876 - val_loss: 1.2659 - val_accuracy: 0.5485\n",
      "Epoch 15/50\n",
      "96/96 [==============================] - 144s 1s/step - loss: 0.7058 - accuracy: 0.7131 - val_loss: 0.9327 - val_accuracy: 0.6306\n",
      "Epoch 16/50\n",
      "96/96 [==============================] - 160s 2s/step - loss: 0.6478 - accuracy: 0.7280 - val_loss: 0.9424 - val_accuracy: 0.6137\n",
      "Epoch 17/50\n",
      "96/96 [==============================] - 1012s 11s/step - loss: 0.5908 - accuracy: 0.7564 - val_loss: 24.3144 - val_accuracy: 0.5342\n",
      "Epoch 18/50\n",
      "96/96 [==============================] - 712s 7s/step - loss: 0.6924 - accuracy: 0.7240 - val_loss: 1.2572 - val_accuracy: 0.6156\n",
      "Epoch 19/50\n",
      "96/96 [==============================] - 1011s 11s/step - loss: 0.6408 - accuracy: 0.7518 - val_loss: 1.0171 - val_accuracy: 0.6124\n",
      "Epoch 20/50\n",
      "96/96 [==============================] - 706s 7s/step - loss: 0.6522 - accuracy: 0.7409 - val_loss: 10.2779 - val_accuracy: 0.5179\n",
      "Epoch 21/50\n",
      "96/96 [==============================] - 1007s 11s/step - loss: 0.8253 - accuracy: 0.6568 - val_loss: 1.6228 - val_accuracy: 0.4664\n",
      "Epoch 22/50\n",
      "96/96 [==============================] - 711s 7s/step - loss: 0.7387 - accuracy: 0.7041 - val_loss: 199.8611 - val_accuracy: 0.5420\n",
      "Epoch 23/50\n",
      "96/96 [==============================] - 1010s 11s/step - loss: 0.8870 - accuracy: 0.6686 - val_loss: 1.2839 - val_accuracy: 0.5779\n",
      "Epoch 24/50\n",
      "96/96 [==============================] - 704s 7s/step - loss: 0.8356 - accuracy: 0.6886 - val_loss: 1.7084 - val_accuracy: 0.5759\n",
      "Epoch 25/50\n",
      "96/96 [==============================] - 1011s 11s/step - loss: 0.7957 - accuracy: 0.7088 - val_loss: 1.6965 - val_accuracy: 0.5355\n",
      "Epoch 26/50\n",
      "96/96 [==============================] - 707s 7s/step - loss: 0.7143 - accuracy: 0.7122 - val_loss: 2.0039 - val_accuracy: 0.5857\n",
      "Epoch 27/50\n",
      "96/96 [==============================] - 703s 7s/step - loss: 0.6385 - accuracy: 0.7450 - val_loss: 1.1485 - val_accuracy: 0.5811\n",
      "Epoch 28/50\n",
      "96/96 [==============================] - 119s 1s/step - loss: 0.5369 - accuracy: 0.7888 - val_loss: 1.3781 - val_accuracy: 0.5863\n",
      "Epoch 29/50\n",
      "96/96 [==============================] - 709s 7s/step - loss: 0.4949 - accuracy: 0.8058 - val_loss: 4.9987 - val_accuracy: 0.3231\n",
      "Epoch 30/50\n",
      "96/96 [==============================] - 710s 7s/step - loss: 0.9476 - accuracy: 0.6296 - val_loss: 1.4301 - val_accuracy: 0.4710\n",
      "Epoch 31/50\n",
      "96/96 [==============================] - 1004s 11s/step - loss: 0.7747 - accuracy: 0.6779 - val_loss: 1.3163 - val_accuracy: 0.6059\n",
      "Epoch 32/50\n",
      "96/96 [==============================] - 703s 7s/step - loss: 0.6944 - accuracy: 0.7152 - val_loss: 1.2980 - val_accuracy: 0.5726\n",
      "Epoch 33/50\n",
      "96/96 [==============================] - 678s 7s/step - loss: 0.6153 - accuracy: 0.7466 - val_loss: 1.2918 - val_accuracy: 0.5915\n",
      "Epoch 34/50\n",
      "96/96 [==============================] - 707s 7s/step - loss: 0.5333 - accuracy: 0.7834 - val_loss: 1.2147 - val_accuracy: 0.6163\n",
      "Epoch 35/50\n",
      "96/96 [==============================] - 1004s 11s/step - loss: 0.4529 - accuracy: 0.8198 - val_loss: 1.3523 - val_accuracy: 0.6111\n",
      "Epoch 36/50\n",
      "96/96 [==============================] - 707s 7s/step - loss: 0.3888 - accuracy: 0.8522 - val_loss: 1.1913 - val_accuracy: 0.6404\n",
      "Epoch 37/50\n",
      "96/96 [==============================] - 708s 7s/step - loss: 0.3251 - accuracy: 0.8762 - val_loss: 1.4414 - val_accuracy: 0.6150\n",
      "Epoch 38/50\n",
      "96/96 [==============================] - 1008s 11s/step - loss: 0.2889 - accuracy: 0.8923 - val_loss: 1.7474 - val_accuracy: 0.6195\n",
      "Epoch 39/50\n",
      "96/96 [==============================] - 705s 7s/step - loss: 0.2455 - accuracy: 0.9060 - val_loss: 1.7211 - val_accuracy: 0.6052\n",
      "Epoch 40/50\n",
      "96/96 [==============================] - 712s 7s/step - loss: 0.2370 - accuracy: 0.9145 - val_loss: 1.5223 - val_accuracy: 0.6130\n",
      "Epoch 41/50\n",
      "96/96 [==============================] - 708s 7s/step - loss: 0.1948 - accuracy: 0.9278 - val_loss: 1.7090 - val_accuracy: 0.5980\n",
      "Epoch 42/50\n",
      "96/96 [==============================] - 707s 7s/step - loss: 0.1882 - accuracy: 0.9281 - val_loss: 1.9029 - val_accuracy: 0.6091\n",
      "Epoch 43/50\n",
      "96/96 [==============================] - 1008s 11s/step - loss: 0.1570 - accuracy: 0.9426 - val_loss: 2.0028 - val_accuracy: 0.6026\n",
      "Epoch 44/50\n",
      "96/96 [==============================] - 706s 7s/step - loss: 0.1295 - accuracy: 0.9552 - val_loss: 1.7912 - val_accuracy: 0.6104\n",
      "Epoch 45/50\n",
      "96/96 [==============================] - 868s 9s/step - loss: 0.1207 - accuracy: 0.9571 - val_loss: 2.1490 - val_accuracy: 0.5603\n",
      "Epoch 46/50\n",
      "96/96 [==============================] - 1004s 11s/step - loss: 0.1273 - accuracy: 0.9536 - val_loss: 2.1162 - val_accuracy: 0.5616\n",
      "Epoch 47/50\n",
      "96/96 [==============================] - 706s 7s/step - loss: 0.1090 - accuracy: 0.9619 - val_loss: 1.7657 - val_accuracy: 0.6091\n",
      "Epoch 48/50\n",
      "96/96 [==============================] - 702s 7s/step - loss: 0.1141 - accuracy: 0.9599 - val_loss: 2.4028 - val_accuracy: 0.5922\n",
      "Epoch 49/50\n",
      "96/96 [==============================] - 788s 8s/step - loss: 0.0939 - accuracy: 0.9656 - val_loss: 2.4567 - val_accuracy: 0.5205\n",
      "Epoch 50/50\n",
      "96/96 [==============================] - 105s 1s/step - loss: 0.0918 - accuracy: 0.9687 - val_loss: 2.4848 - val_accuracy: 0.5629\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2988888d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "epochs = 50\n",
    "model.fit(train_dataset, epochs=epochs, validation_data=valid_dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf2a4877",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 4s 130ms/step - loss: 11.2915 - accuracy: 0.2384\n",
      "27/27 [==============================] - 4s 129ms/step\n",
      "Test Loss: 11.291510581970215\n",
      "Test Accuracy: 0.23843416571617126\n",
      "Accuracy: 0.23843416370106763\n",
      "F1 Score: 0.2394178209500662\n",
      "Confusion Matrix:\n",
      "[[  0 334 119   8   3]\n",
      " [  0 355 565   3   2]\n",
      " [  0 137  27   9   4]\n",
      " [  0  57  30  20  13]\n",
      " [  0   0   0   0   0]]\n",
      "cohen_kappa_score :\n",
      "0.13723708921782896\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Evaluate the model on the test dataset\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test_categorical))\n",
    "test_dataset = test_dataset.batch(batch_size)\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(test_dataset)\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(test_dataset)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(Y_test, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(Y_test, predicted_labels)\n",
    "\n",
    "print(f\"Test Loss: {test_loss}\")\n",
    "print(f\"Test Accuracy: {test_accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "print(\"cohen_kappa_score :\")\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "k = cohen_kappa_score(Y_test, predicted_labels, weights='quadratic')\n",
    "print(k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0c7b45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c30219e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83c1011",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
