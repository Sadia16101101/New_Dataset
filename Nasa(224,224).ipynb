{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08fa2888",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNet\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38f7fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Define the paths to your dataset\n",
    "dataset_dir = \"/Users/sadianasrintisha/Desktop/Dataset/NASA Worldview./understanding_cloud_organization\"\n",
    "train_images_dir = os.path.join(dataset_dir, \"train_images\")\n",
    "test_images_dir = os.path.join(dataset_dir, \"test_images\")\n",
    "train_csv_path = os.path.join(dataset_dir, \"train.csv\")\n",
    "\n",
    "# Create empty lists to store images and labels\n",
    "X_train = []\n",
    "Y_train = []\n",
    "X_test = []\n",
    "Y_test = []  # Placeholder for test labels\n",
    "\n",
    "# Read the CSV file to get image-label pairs\n",
    "df = pd.read_csv(train_csv_path)\n",
    "\n",
    "# Function to read, resize, and append images to X_train and labels to Y_train\n",
    "def process_images_and_labels(image_dir, label_df, label_encoder, is_test=False):\n",
    "    for index, row in label_df.iterrows():\n",
    "        image_path = os.path.join(image_dir, row['Image_Label'].split('_')[0])\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = image.resize((224, 224))\n",
    "        image_array = np.array(image)\n",
    "        \n",
    "        if is_test:\n",
    "            X_test.append(image_array)\n",
    "            # For test data, you can use a placeholder or any appropriate label.\n",
    "            Y_test.append(0)  # Placeholder label for test images\n",
    "        else:\n",
    "            X_train.append(image_array)\n",
    "            label = row['EncodedPixels'] if not pd.isna(row['EncodedPixels']) else '0'\n",
    "            Y_train.append(label_encoder.transform([label])[0])\n",
    "\n",
    "# Initialize the label encoder\n",
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df['EncodedPixels'].fillna('0'))\n",
    "\n",
    "# Process the training images and labels\n",
    "process_images_and_labels(train_images_dir, df, label_encoder)\n",
    "\n",
    "# Process the test images\n",
    "test_image_files = os.listdir(test_images_dir)\n",
    "process_images_and_labels(test_images_dir, pd.DataFrame({'Image_Label': test_image_files}), label_encoder, is_test=True)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "905b0338",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train: (22184, 224, 224, 3)\n",
      "Shape of Y_train: (22184,)\n",
      "Shape of X_test: (3698, 224, 224, 3)\n",
      "Shape of Y_test: (3698,)\n"
     ]
    }
   ],
   "source": [
    "print(\"Shape of X_train:\", X_train.shape)\n",
    "print(\"Shape of Y_train:\", Y_train.shape)\n",
    "print(\"Shape of X_test:\", X_test.shape)\n",
    "print(\"Shape of Y_test:\", Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06ba483b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c488ec5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GlobalAveragePooling2D, Dense\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.optimizers.legacy import Adam as LegacyAdam\n",
    "\n",
    "from keras.utils import to_categorical  # Add this import\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "Y_train_encoded = label_encoder.fit_transform(Y_train)\n",
    "\n",
    "# Use to_categorical to one-hot encode the integer labels\n",
    "num_classes = len(label_encoder.classes_)  # Number of unique classes\n",
    "Y_train_one_hot = to_categorical(Y_train_encoded, num_classes=num_classes)\n",
    "\n",
    "# Split your training data into training and validation sets\n",
    "X_train, X_val, Y_train_one_hot, Y_val_one_hot = train_test_split(\n",
    "    X_train, Y_train_one_hot, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    " \n",
    "optimizer = LegacyAdam(learning_rate=0.001)\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(num_classes, activation='softmax'))  # Change the number of units and activation\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f83c1011",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "278/278 [==============================] - 12488s 45s/step - loss: 6.2632 - accuracy: 0.4662 - val_loss: 11.6813 - val_accuracy: 0.4591\n",
      "Epoch 2/50\n",
      "278/278 [==============================] - 15175s 55s/step - loss: 5.5440 - accuracy: 0.4683 - val_loss: 6.9003 - val_accuracy: 0.4591\n",
      "Epoch 3/50\n",
      "278/278 [==============================] - 6457s 23s/step - loss: 4.5767 - accuracy: 0.4682 - val_loss: 7.2362 - val_accuracy: 0.4591\n",
      "Epoch 4/50\n",
      "278/278 [==============================] - 6193s 21s/step - loss: 3.2407 - accuracy: 0.4614 - val_loss: 9.3379 - val_accuracy: 0.4517\n",
      "Epoch 5/50\n",
      "278/278 [==============================] - 28993s 105s/step - loss: 2.3745 - accuracy: 0.4102 - val_loss: 9.4874 - val_accuracy: 0.4453\n",
      "Epoch 6/50\n",
      "278/278 [==============================] - 5152s 19s/step - loss: 1.9900 - accuracy: 0.3806 - val_loss: 9.9369 - val_accuracy: 0.3946\n",
      "Epoch 7/50\n",
      "278/278 [==============================] - 2526s 9s/step - loss: 1.7907 - accuracy: 0.3652 - val_loss: 10.1667 - val_accuracy: 0.4494\n",
      "Epoch 8/50\n",
      "278/278 [==============================] - 6102s 22s/step - loss: 1.6765 - accuracy: 0.3609 - val_loss: 10.0573 - val_accuracy: 0.4136\n",
      "Epoch 9/50\n",
      "278/278 [==============================] - 38130s 136s/step - loss: 1.5933 - accuracy: 0.3610 - val_loss: 10.3104 - val_accuracy: 0.3387\n",
      "Epoch 10/50\n",
      "278/278 [==============================] - 4415s 16s/step - loss: 1.5335 - accuracy: 0.3558 - val_loss: 10.2531 - val_accuracy: 0.3419\n",
      "Epoch 11/50\n",
      "278/278 [==============================] - 26767s 97s/step - loss: 1.4909 - accuracy: 0.3600 - val_loss: 10.8238 - val_accuracy: 0.3270\n",
      "Epoch 12/50\n",
      "278/278 [==============================] - 5822s 21s/step - loss: 1.4610 - accuracy: 0.3553 - val_loss: 10.2290 - val_accuracy: 0.4339\n",
      "Epoch 13/50\n",
      "278/278 [==============================] - 3760s 14s/step - loss: 1.4267 - accuracy: 0.3568 - val_loss: 10.5130 - val_accuracy: 0.4041\n",
      "Epoch 14/50\n",
      "278/278 [==============================] - 2705s 10s/step - loss: 1.4017 - accuracy: 0.3611 - val_loss: 10.4957 - val_accuracy: 0.4037\n",
      "Epoch 15/50\n",
      "278/278 [==============================] - 2828s 10s/step - loss: 1.3824 - accuracy: 0.3593 - val_loss: 10.3410 - val_accuracy: 0.3442\n",
      "Epoch 16/50\n",
      "278/278 [==============================] - 4858s 18s/step - loss: 1.3651 - accuracy: 0.3590 - val_loss: 10.5496 - val_accuracy: 0.3223\n",
      "Epoch 17/50\n",
      "278/278 [==============================] - 7002s 25s/step - loss: 1.3475 - accuracy: 0.3593 - val_loss: 10.5826 - val_accuracy: 0.2630\n",
      "Epoch 18/50\n",
      "278/278 [==============================] - 8741s 32s/step - loss: 1.3307 - accuracy: 0.3610 - val_loss: 10.1056 - val_accuracy: 0.3254\n",
      "Epoch 19/50\n",
      "278/278 [==============================] - 4427s 16s/step - loss: 1.3202 - accuracy: 0.3634 - val_loss: 10.8288 - val_accuracy: 0.2457\n",
      "Epoch 20/50\n",
      "278/278 [==============================] - 10969s 40s/step - loss: 1.3082 - accuracy: 0.3641 - val_loss: 10.6340 - val_accuracy: 0.3279\n",
      "Epoch 21/50\n",
      "278/278 [==============================] - 6897s 25s/step - loss: 1.2984 - accuracy: 0.3651 - val_loss: 10.4841 - val_accuracy: 0.3683\n",
      "Epoch 22/50\n",
      "278/278 [==============================] - 4642s 17s/step - loss: 1.2883 - accuracy: 0.3674 - val_loss: 10.6711 - val_accuracy: 0.3593\n",
      "Epoch 23/50\n",
      "278/278 [==============================] - 23749s 86s/step - loss: 1.2804 - accuracy: 0.3642 - val_loss: 10.9078 - val_accuracy: 0.3063\n",
      "Epoch 24/50\n",
      "278/278 [==============================] - 2953s 11s/step - loss: 1.2687 - accuracy: 0.3705 - val_loss: 10.7949 - val_accuracy: 0.3865\n",
      "Epoch 25/50\n",
      "278/278 [==============================] - 4466s 16s/step - loss: 1.2621 - accuracy: 0.3657 - val_loss: 10.8377 - val_accuracy: 0.2484\n",
      "Epoch 26/50\n",
      "278/278 [==============================] - 26815s 97s/step - loss: 1.2525 - accuracy: 0.3701 - val_loss: 10.6591 - val_accuracy: 0.3466\n",
      "Epoch 27/50\n",
      "278/278 [==============================] - 5450s 20s/step - loss: 1.2442 - accuracy: 0.3715 - val_loss: 10.8719 - val_accuracy: 0.3198\n",
      "Epoch 28/50\n",
      "278/278 [==============================] - 2917s 10s/step - loss: 1.2359 - accuracy: 0.3723 - val_loss: 10.5333 - val_accuracy: 0.3996\n",
      "Epoch 29/50\n",
      "278/278 [==============================] - 2884s 10s/step - loss: 1.2296 - accuracy: 0.3746 - val_loss: 10.9867 - val_accuracy: 0.2434\n",
      "Epoch 30/50\n",
      "278/278 [==============================] - 5345s 19s/step - loss: 1.2237 - accuracy: 0.3719 - val_loss: 10.9959 - val_accuracy: 0.3444\n",
      "Epoch 31/50\n",
      "278/278 [==============================] - 6293s 23s/step - loss: 1.2129 - accuracy: 0.3774 - val_loss: 10.8933 - val_accuracy: 0.3453\n",
      "Epoch 32/50\n",
      "278/278 [==============================] - 4583s 17s/step - loss: 1.2091 - accuracy: 0.3753 - val_loss: 10.9264 - val_accuracy: 0.3115\n",
      "Epoch 33/50\n",
      "278/278 [==============================] - 4763s 17s/step - loss: 1.2009 - accuracy: 0.3760 - val_loss: 11.0859 - val_accuracy: 0.3245\n",
      "Epoch 34/50\n",
      "278/278 [==============================] - 7396s 27s/step - loss: 1.1956 - accuracy: 0.3775 - val_loss: 10.8002 - val_accuracy: 0.2752\n",
      "Epoch 35/50\n",
      "278/278 [==============================] - 9863s 36s/step - loss: 1.1907 - accuracy: 0.3820 - val_loss: 10.8878 - val_accuracy: 0.3054\n",
      "Epoch 36/50\n",
      "278/278 [==============================] - 5927s 21s/step - loss: 1.1829 - accuracy: 0.3821 - val_loss: 10.8516 - val_accuracy: 0.3818\n",
      "Epoch 37/50\n",
      "278/278 [==============================] - 2952s 11s/step - loss: 1.1784 - accuracy: 0.3830 - val_loss: 11.0010 - val_accuracy: 0.2937\n",
      "Epoch 38/50\n",
      "278/278 [==============================] - 33115s 120s/step - loss: 1.1730 - accuracy: 0.3816 - val_loss: 10.6789 - val_accuracy: 0.3462\n",
      "Epoch 39/50\n",
      "278/278 [==============================] - 3757s 14s/step - loss: 1.1666 - accuracy: 0.3844 - val_loss: 10.8292 - val_accuracy: 0.2551\n",
      "Epoch 40/50\n",
      "278/278 [==============================] - 3218s 12s/step - loss: 1.1633 - accuracy: 0.3865 - val_loss: 11.1562 - val_accuracy: 0.2959\n",
      "Epoch 41/50\n",
      "278/278 [==============================] - 7045s 25s/step - loss: 1.1594 - accuracy: 0.3890 - val_loss: 10.6044 - val_accuracy: 0.3550\n",
      "Epoch 42/50\n",
      "278/278 [==============================] - 5942s 21s/step - loss: 1.1548 - accuracy: 0.3859 - val_loss: 10.7830 - val_accuracy: 0.3016\n",
      "Epoch 43/50\n",
      "278/278 [==============================] - 14099s 51s/step - loss: 1.1501 - accuracy: 0.3874 - val_loss: 10.8376 - val_accuracy: 0.2939\n",
      "Epoch 44/50\n",
      "278/278 [==============================] - 11900s 43s/step - loss: 1.1431 - accuracy: 0.3895 - val_loss: 10.8625 - val_accuracy: 0.1927\n",
      "Epoch 45/50\n",
      "278/278 [==============================] - 11821s 43s/step - loss: 1.1407 - accuracy: 0.3927 - val_loss: 10.9555 - val_accuracy: 0.2283\n",
      "Epoch 46/50\n",
      "278/278 [==============================] - 7926s 29s/step - loss: 1.1344 - accuracy: 0.3922 - val_loss: 10.8306 - val_accuracy: 0.2463\n",
      "Epoch 47/50\n",
      "278/278 [==============================] - 2790s 10s/step - loss: 1.1321 - accuracy: 0.3992 - val_loss: 10.8880 - val_accuracy: 0.2770\n",
      "Epoch 48/50\n",
      "278/278 [==============================] - 3610s 13s/step - loss: 1.1294 - accuracy: 0.3927 - val_loss: 10.8459 - val_accuracy: 0.3151\n",
      "Epoch 49/50\n",
      "278/278 [==============================] - 8869s 32s/step - loss: 1.1240 - accuracy: 0.3943 - val_loss: 10.8168 - val_accuracy: 0.2621\n",
      "Epoch 50/50\n",
      "278/278 [==============================] - 9601s 35s/step - loss: 1.1208 - accuracy: 0.3955 - val_loss: 10.8339 - val_accuracy: 0.2515\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x16ea259d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, Y_train_one_hot, batch_size=64, epochs=50, validation_data=(X_val, Y_val_one_hot))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d00741f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 101s 865ms/step\n",
      "Accuracy: 0.9989183342347214\n",
      "F1 Score (Micro): 0.9989183342347214\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on X_test\n",
    "y_pred_prob = model.predict(X_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# One-hot encode the true labels in Y_test if it's not already one-hot encoded\n",
    "if len(Y_test.shape) == 1:  # Check if Y_test is 1D\n",
    "    num_classes = len(np.unique(Y_test))\n",
    "    Y_test_encoded = np.zeros((len(Y_test), num_classes))\n",
    "    Y_test_encoded[np.arange(len(Y_test)), Y_test] = 1\n",
    "else:\n",
    "    Y_test_encoded = Y_test  # Y_test is already one-hot encoded\n",
    "\n",
    "# Convert Y_test_encoded to predicted labels format\n",
    "y_test_labels = np.argmax(Y_test_encoded, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2936159",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
