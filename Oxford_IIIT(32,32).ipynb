{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6efb0411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\sadia_tisha1\\tensorflow_datasets\\oxford_iiit_pet\\3.2.0...\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f4d2026c052419ab28726d9b7f45de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Completed...: 0 url [00:00, ? url/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5a3c4bab6234698b8db21a8a76eed4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Dl Size...: 0 MiB [00:00, ? MiB/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "879af24ce60d48a9b49729cbff6c93e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extraction completed...: 0 file [00:00, ? file/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating splits...:   0%|          | 0/2 [00:00<?, ? splits/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\sadia_tisha1\\tensorflow_datasets\\oxford_iiit_pet\\3.2.0.incompleteNWH99X\\oxford_iiit_pet-tra…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test examples...: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Shuffling C:\\Users\\sadia_tisha1\\tensorflow_datasets\\oxford_iiit_pet\\3.2.0.incompleteNWH99X\\oxford_iiit_pet-tes…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mDataset oxford_iiit_pet downloaded and prepared to C:\\Users\\sadia_tisha1\\tensorflow_datasets\\oxford_iiit_pet\\3.2.0. Subsequent calls will reuse this data.\u001b[0m\n",
      "Images shape: (64, 32, 32, 3)\n",
      "Labels shape: (64, 37)\n",
      "Images shape: (64, 32, 32, 3)\n",
      "Labels shape: (64, 37)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "# Load the Oxford-IIIT Pet dataset\n",
    "(ds_train, ds_test), ds_info = tfds.load('oxford_iiit_pet', split=['train', 'test'], as_supervised=True, with_info=True)\n",
    "\n",
    "# Define a function to resize images\n",
    "def resize_image(image, label):\n",
    "    image = tf.image.resize(image, (32, 32))\n",
    "    return image, label\n",
    "\n",
    "# Apply resizing to the dataset\n",
    "ds_train = ds_train.map(resize_image)\n",
    "ds_test = ds_test.map(resize_image)\n",
    "\n",
    "# Normalize pixel values to be in the range [0, 1]\n",
    "ds_train = ds_train.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "ds_test = ds_test.map(lambda x, y: (tf.cast(x, tf.float32) / 255.0, y))\n",
    "\n",
    "# Shuffle and batch the datasets\n",
    "ds_train = ds_train.shuffle(10000).batch(64)\n",
    "ds_test = ds_test.batch(64)\n",
    "\n",
    "# Convert labels to categorical format\n",
    "def categorical_labels(images, labels):\n",
    "    return images, tf.one_hot(labels, depth=37)  # 37 classes in Oxford-IIIT Pet dataset\n",
    "\n",
    "ds_train = ds_train.map(categorical_labels)\n",
    "ds_test = ds_test.map(categorical_labels)\n",
    "\n",
    "# Verify the shapes\n",
    "for images, labels in ds_train.take(1):\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n",
    "\n",
    "for images, labels in ds_test.take(1):\n",
    "    print(\"Images shape:\", images.shape)\n",
    "    print(\"Labels shape:\", labels.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91a129e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 120s 2s/step - loss: 4.2437 - accuracy: 0.0565\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c6dd3e26d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "    \n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(37, activation='softmax'))  # Change the number of units and activation\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit(ds_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "052538fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "58/58 [==============================] - 115s 2s/step - loss: 3.5412 - accuracy: 0.1196\n",
      "Epoch 2/50\n",
      "58/58 [==============================] - 219s 4s/step - loss: 3.3026 - accuracy: 0.1560\n",
      "Epoch 3/50\n",
      "58/58 [==============================] - 293s 5s/step - loss: 2.9172 - accuracy: 0.2484\n",
      "Epoch 4/50\n",
      "58/58 [==============================] - 293s 5s/step - loss: 2.7654 - accuracy: 0.3057\n",
      "Epoch 5/50\n",
      "58/58 [==============================] - 290s 5s/step - loss: 2.8470 - accuracy: 0.2995\n",
      "Epoch 6/50\n",
      "58/58 [==============================] - 192s 3s/step - loss: 2.8860 - accuracy: 0.2897\n",
      "Epoch 7/50\n",
      "58/58 [==============================] - 303s 5s/step - loss: 3.2725 - accuracy: 0.2435\n",
      "Epoch 8/50\n",
      "58/58 [==============================] - 306s 5s/step - loss: 2.8541 - accuracy: 0.3054\n",
      "Epoch 9/50\n",
      "58/58 [==============================] - 294s 5s/step - loss: 2.8222 - accuracy: 0.2755\n",
      "Epoch 10/50\n",
      "58/58 [==============================] - 295s 5s/step - loss: 2.3775 - accuracy: 0.3984\n",
      "Epoch 11/50\n",
      "58/58 [==============================] - 302s 5s/step - loss: 2.3684 - accuracy: 0.4269\n",
      "Epoch 12/50\n",
      "58/58 [==============================] - 299s 5s/step - loss: 2.0780 - accuracy: 0.4986\n",
      "Epoch 13/50\n",
      "58/58 [==============================] - 294s 5s/step - loss: 1.9694 - accuracy: 0.5174\n",
      "Epoch 14/50\n",
      "58/58 [==============================] - 290s 5s/step - loss: 1.7806 - accuracy: 0.5658\n",
      "Epoch 15/50\n",
      "58/58 [==============================] - 301s 5s/step - loss: 2.4659 - accuracy: 0.4076\n",
      "Epoch 16/50\n",
      "58/58 [==============================] - 297s 5s/step - loss: 2.8514 - accuracy: 0.3465\n",
      "Epoch 17/50\n",
      "58/58 [==============================] - 295s 5s/step - loss: 2.4104 - accuracy: 0.4280\n",
      "Epoch 18/50\n",
      "58/58 [==============================] - 282s 5s/step - loss: 1.5995 - accuracy: 0.6079\n",
      "Epoch 19/50\n",
      "58/58 [==============================] - 296s 5s/step - loss: 1.3783 - accuracy: 0.6603\n",
      "Epoch 20/50\n",
      "58/58 [==============================] - 301s 5s/step - loss: 0.9503 - accuracy: 0.7821\n",
      "Epoch 21/50\n",
      "58/58 [==============================] - 294s 5s/step - loss: 0.8680 - accuracy: 0.8280\n",
      "Epoch 22/50\n",
      "58/58 [==============================] - 233s 4s/step - loss: 0.8330 - accuracy: 0.8247\n",
      "Epoch 23/50\n",
      "58/58 [==============================] - 250s 4s/step - loss: 1.0684 - accuracy: 0.7340\n",
      "Epoch 24/50\n",
      "58/58 [==============================] - 300s 5s/step - loss: 1.3173 - accuracy: 0.6731\n",
      "Epoch 25/50\n",
      "58/58 [==============================] - 295s 5s/step - loss: 0.6419 - accuracy: 0.8484\n",
      "Epoch 26/50\n",
      "58/58 [==============================] - 319s 5s/step - loss: 0.4657 - accuracy: 0.9163\n",
      "Epoch 27/50\n",
      "58/58 [==============================] - 225s 4s/step - loss: 0.2786 - accuracy: 0.9668\n",
      "Epoch 28/50\n",
      "58/58 [==============================] - 277s 5s/step - loss: 0.1738 - accuracy: 0.9753\n",
      "Epoch 29/50\n",
      "58/58 [==============================] - 301s 5s/step - loss: 0.0815 - accuracy: 0.9924\n",
      "Epoch 30/50\n",
      "58/58 [==============================] - 295s 5s/step - loss: 0.2195 - accuracy: 0.9707\n",
      "Epoch 31/50\n",
      "58/58 [==============================] - 245s 4s/step - loss: 0.1990 - accuracy: 0.9766\n",
      "Epoch 32/50\n",
      "58/58 [==============================] - 191s 3s/step - loss: 0.3654 - accuracy: 0.9391\n",
      "Epoch 33/50\n",
      "58/58 [==============================] - 261s 4s/step - loss: 0.2896 - accuracy: 0.9399\n",
      "Epoch 34/50\n",
      "58/58 [==============================] - 309s 5s/step - loss: 0.1240 - accuracy: 0.9769\n",
      "Epoch 35/50\n",
      "58/58 [==============================] - 304s 5s/step - loss: 0.2897 - accuracy: 0.9448\n",
      "Epoch 36/50\n",
      "58/58 [==============================] - 237s 4s/step - loss: 0.2655 - accuracy: 0.9413\n",
      "Epoch 37/50\n",
      "58/58 [==============================] - 182s 3s/step - loss: 0.2198 - accuracy: 0.9663\n",
      "Epoch 38/50\n",
      "58/58 [==============================] - 189s 3s/step - loss: 0.1188 - accuracy: 0.9851\n",
      "Epoch 39/50\n",
      "58/58 [==============================] - 261s 4s/step - loss: 0.1772 - accuracy: 0.9715\n",
      "Epoch 40/50\n",
      "58/58 [==============================] - 301s 5s/step - loss: 0.3285 - accuracy: 0.9435\n",
      "Epoch 41/50\n",
      "58/58 [==============================] - 293s 5s/step - loss: 0.1843 - accuracy: 0.9543\n",
      "Epoch 42/50\n",
      "58/58 [==============================] - 194s 3s/step - loss: 0.4437 - accuracy: 0.8986\n",
      "Epoch 43/50\n",
      "58/58 [==============================] - 186s 3s/step - loss: 0.2514 - accuracy: 0.9465\n",
      "Epoch 44/50\n",
      "58/58 [==============================] - 202s 3s/step - loss: 0.5587 - accuracy: 0.8731\n",
      "Epoch 45/50\n",
      "58/58 [==============================] - 288s 5s/step - loss: 0.4036 - accuracy: 0.8981\n",
      "Epoch 46/50\n",
      "58/58 [==============================] - 294s 5s/step - loss: 0.2105 - accuracy: 0.9535\n",
      "Epoch 47/50\n",
      "58/58 [==============================] - 270s 5s/step - loss: 0.1627 - accuracy: 0.9726\n",
      "Epoch 48/50\n",
      "58/58 [==============================] - 181s 3s/step - loss: 0.0902 - accuracy: 0.9821\n",
      "Epoch 49/50\n",
      "58/58 [==============================] - 200s 3s/step - loss: 0.1746 - accuracy: 0.9606\n",
      "Epoch 50/50\n",
      "58/58 [==============================] - 253s 4s/step - loss: 0.0766 - accuracy: 0.9832\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c68003a370>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ds_train, batch_size=64, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7b29618",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.17116380485145816\n",
      "Accuracy: 0.17116380485145816\n",
      "F1 Score: 0.1659174869942088\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "# Make predictions on the test dataset\n",
    "predictions = model.predict(ds_test)\n",
    "\n",
    "# Convert one-hot encoded predictions back to class labels\n",
    "predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "# Manually generate ground truth labels for evaluation\n",
    "true_labels = []\n",
    "for _, label in ds_test:\n",
    "    true_labels.extend(label.numpy())\n",
    "\n",
    "true_labels = np.argmax(true_labels, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels, average='weighted')\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "\n",
    "# Assuming you have test_loss and test_accuracy available\n",
    "# If not, you'll need to calculate them based on your model and test dataset\n",
    "print(f\"Test Accuracy: {accuracy}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"F1 Score: {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2925df83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682f9447",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d19d42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "606146b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095ba2ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9efd4eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287aff3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e68d10e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de2851ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43165ad8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce09e57c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e6ead7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
