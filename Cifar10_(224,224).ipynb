{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a71b0ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers.legacy import Adam as LegacyAdam\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f497dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data generator with image augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Define the model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = LegacyAdam(learning_rate=0.001)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Create data generators for training and validation\n",
    "train_generator = datagen.flow(x_train, y_train, batch_size=64)\n",
    "validation_generator = datagen.flow(x_test, y_test, batch_size=64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1b814d7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "782/782 [==============================] - 687s 876ms/step - loss: 1.9540 - accuracy: 0.3613 - val_loss: 200.1228 - val_accuracy: 0.1000\n",
      "Epoch 2/50\n",
      "782/782 [==============================] - 966s 1s/step - loss: 1.8532 - accuracy: 0.3816 - val_loss: 3.5717 - val_accuracy: 0.1000\n",
      "Epoch 3/50\n",
      "782/782 [==============================] - 1798s 2s/step - loss: 1.8122 - accuracy: 0.3907 - val_loss: 137.9489 - val_accuracy: 0.0976\n",
      "Epoch 4/50\n",
      "782/782 [==============================] - 3360s 4s/step - loss: 1.6495 - accuracy: 0.4411 - val_loss: 2.5760 - val_accuracy: 0.1578\n",
      "Epoch 5/50\n",
      "782/782 [==============================] - 4665s 6s/step - loss: 1.5260 - accuracy: 0.4734 - val_loss: 4.1086 - val_accuracy: 0.1958\n",
      "Epoch 6/50\n",
      "782/782 [==============================] - 669s 856ms/step - loss: 1.8470 - accuracy: 0.4050 - val_loss: 1332.9869 - val_accuracy: 0.1000\n",
      "Epoch 7/50\n",
      "782/782 [==============================] - 696s 890ms/step - loss: 1.8889 - accuracy: 0.3807 - val_loss: 2.2319 - val_accuracy: 0.2421\n",
      "Epoch 8/50\n",
      "782/782 [==============================] - 2802s 4s/step - loss: 1.7507 - accuracy: 0.4100 - val_loss: 2.6456 - val_accuracy: 0.1698\n",
      "Epoch 9/50\n",
      "782/782 [==============================] - 6607s 8s/step - loss: 1.5025 - accuracy: 0.4805 - val_loss: 4.9723 - val_accuracy: 0.1127\n",
      "Epoch 10/50\n",
      "782/782 [==============================] - 647s 827ms/step - loss: 1.4402 - accuracy: 0.5021 - val_loss: 5.3535 - val_accuracy: 0.1249\n",
      "Epoch 11/50\n",
      "782/782 [==============================] - 690s 883ms/step - loss: 1.3717 - accuracy: 0.5228 - val_loss: 6.4787 - val_accuracy: 0.1279\n",
      "Epoch 12/50\n",
      "782/782 [==============================] - 726s 928ms/step - loss: 1.3570 - accuracy: 0.5291 - val_loss: 3.0302 - val_accuracy: 0.1482\n",
      "Epoch 13/50\n",
      "782/782 [==============================] - 721s 922ms/step - loss: 1.2478 - accuracy: 0.5600 - val_loss: 5.9011 - val_accuracy: 0.1010\n",
      "Epoch 14/50\n",
      "782/782 [==============================] - 722s 923ms/step - loss: 1.1942 - accuracy: 0.5823 - val_loss: 6.8887 - val_accuracy: 0.1000\n",
      "Epoch 15/50\n",
      "782/782 [==============================] - 746s 954ms/step - loss: 1.1237 - accuracy: 0.6053 - val_loss: 5.1467 - val_accuracy: 0.1397\n",
      "Epoch 16/50\n",
      "782/782 [==============================] - 3495s 4s/step - loss: 1.0992 - accuracy: 0.6178 - val_loss: 6.4083 - val_accuracy: 0.1011\n",
      "Epoch 17/50\n",
      "782/782 [==============================] - 681s 871ms/step - loss: 1.0433 - accuracy: 0.6385 - val_loss: 3.5172 - val_accuracy: 0.1429\n",
      "Epoch 18/50\n",
      "782/782 [==============================] - 762s 974ms/step - loss: 1.0650 - accuracy: 0.6279 - val_loss: 3.1201 - val_accuracy: 0.1271\n",
      "Epoch 19/50\n",
      "782/782 [==============================] - 736s 941ms/step - loss: 0.9842 - accuracy: 0.6558 - val_loss: 4.5781 - val_accuracy: 0.1018\n",
      "Epoch 20/50\n",
      "782/782 [==============================] - 750s 959ms/step - loss: 0.9615 - accuracy: 0.6648 - val_loss: 8.5998 - val_accuracy: 0.1352\n",
      "Epoch 21/50\n",
      "782/782 [==============================] - 750s 959ms/step - loss: 0.9226 - accuracy: 0.6778 - val_loss: 3.4012 - val_accuracy: 0.1147\n",
      "Epoch 22/50\n",
      "782/782 [==============================] - 754s 964ms/step - loss: 0.9000 - accuracy: 0.6877 - val_loss: 4.2958 - val_accuracy: 0.1031\n",
      "Epoch 23/50\n",
      "782/782 [==============================] - 742s 948ms/step - loss: 0.8695 - accuracy: 0.6983 - val_loss: 3.9624 - val_accuracy: 0.0917\n",
      "Epoch 24/50\n",
      "782/782 [==============================] - 893s 1s/step - loss: 0.8609 - accuracy: 0.7021 - val_loss: 3.7014 - val_accuracy: 0.1032\n",
      "Epoch 25/50\n",
      "782/782 [==============================] - 1072s 1s/step - loss: 0.8442 - accuracy: 0.7061 - val_loss: 4.3082 - val_accuracy: 0.1528\n",
      "Epoch 26/50\n",
      "782/782 [==============================] - 1070s 1s/step - loss: 0.8272 - accuracy: 0.7136 - val_loss: 3.9841 - val_accuracy: 0.1286\n",
      "Epoch 27/50\n",
      "782/782 [==============================] - 1078s 1s/step - loss: 0.8169 - accuracy: 0.7175 - val_loss: 6.1596 - val_accuracy: 0.1002\n",
      "Epoch 28/50\n",
      "782/782 [==============================] - 1115s 1s/step - loss: 0.7752 - accuracy: 0.7293 - val_loss: 6.1407 - val_accuracy: 0.1019\n",
      "Epoch 29/50\n",
      "782/782 [==============================] - 2333s 3s/step - loss: 0.7862 - accuracy: 0.7278 - val_loss: 7.0540 - val_accuracy: 0.0663\n",
      "Epoch 30/50\n",
      "782/782 [==============================] - 1149s 1s/step - loss: 0.7654 - accuracy: 0.7359 - val_loss: 5.2454 - val_accuracy: 0.1084\n",
      "Epoch 31/50\n",
      "782/782 [==============================] - 1134s 1s/step - loss: 0.7441 - accuracy: 0.7431 - val_loss: 4.7100 - val_accuracy: 0.1116\n",
      "Epoch 32/50\n",
      "782/782 [==============================] - 952s 1s/step - loss: 0.7379 - accuracy: 0.7453 - val_loss: 3.7212 - val_accuracy: 0.1104\n",
      "Epoch 33/50\n",
      "782/782 [==============================] - 4255s 5s/step - loss: 0.7185 - accuracy: 0.7531 - val_loss: 2.6552 - val_accuracy: 0.1953\n",
      "Epoch 34/50\n",
      "782/782 [==============================] - 771s 986ms/step - loss: 0.7283 - accuracy: 0.7488 - val_loss: 4.8723 - val_accuracy: 0.0947\n",
      "Epoch 35/50\n",
      "782/782 [==============================] - 903s 1s/step - loss: 0.6986 - accuracy: 0.7585 - val_loss: 4.7982 - val_accuracy: 0.0594\n",
      "Epoch 36/50\n",
      "782/782 [==============================] - 1145s 1s/step - loss: 0.6980 - accuracy: 0.7588 - val_loss: 7.2672 - val_accuracy: 0.0981\n",
      "Epoch 37/50\n",
      "782/782 [==============================] - 1113s 1s/step - loss: 0.6865 - accuracy: 0.7625 - val_loss: 3.5172 - val_accuracy: 0.1099\n",
      "Epoch 38/50\n",
      "782/782 [==============================] - 1447s 2s/step - loss: 0.6940 - accuracy: 0.7604 - val_loss: 3.0291 - val_accuracy: 0.2377\n",
      "Epoch 39/50\n",
      "782/782 [==============================] - 1301s 2s/step - loss: 0.6762 - accuracy: 0.7674 - val_loss: 5.5340 - val_accuracy: 0.1007\n",
      "Epoch 40/50\n",
      "782/782 [==============================] - 5186s 7s/step - loss: 0.6530 - accuracy: 0.7743 - val_loss: 4.5336 - val_accuracy: 0.1450\n",
      "Epoch 41/50\n",
      "782/782 [==============================] - 5979s 8s/step - loss: 0.6391 - accuracy: 0.7765 - val_loss: 4.3560 - val_accuracy: 0.1291\n",
      "Epoch 42/50\n",
      "782/782 [==============================] - 6533s 8s/step - loss: 0.6521 - accuracy: 0.7726 - val_loss: 5.0843 - val_accuracy: 0.1198\n",
      "Epoch 43/50\n",
      "782/782 [==============================] - 6126s 8s/step - loss: 0.6470 - accuracy: 0.7775 - val_loss: 3.2219 - val_accuracy: 0.1780\n",
      "Epoch 44/50\n",
      "782/782 [==============================] - 3088s 4s/step - loss: 0.6242 - accuracy: 0.7842 - val_loss: 5.5231 - val_accuracy: 0.1221\n",
      "Epoch 45/50\n",
      "782/782 [==============================] - 1309s 2s/step - loss: 0.6288 - accuracy: 0.7831 - val_loss: 4.5737 - val_accuracy: 0.1197\n",
      "Epoch 46/50\n",
      "782/782 [==============================] - 1341s 2s/step - loss: 0.6109 - accuracy: 0.7897 - val_loss: 3.4400 - val_accuracy: 0.1608\n",
      "Epoch 47/50\n",
      "782/782 [==============================] - 1421s 2s/step - loss: 0.6057 - accuracy: 0.7897 - val_loss: 6.3519 - val_accuracy: 0.1429\n",
      "Epoch 48/50\n",
      "782/782 [==============================] - 2211s 3s/step - loss: 0.6032 - accuracy: 0.7925 - val_loss: 6.6957 - val_accuracy: 0.0999\n",
      "Epoch 49/50\n",
      "782/782 [==============================] - 1255s 2s/step - loss: 0.6114 - accuracy: 0.7896 - val_loss: 3.5696 - val_accuracy: 0.1268\n",
      "Epoch 50/50\n",
      "782/782 [==============================] - 2326s 3s/step - loss: 0.6002 - accuracy: 0.7940 - val_loss: 5.1893 - val_accuracy: 0.1165\n",
      "157/157 [==============================] - 33s 213ms/step - loss: 5.1790 - accuracy: 0.1193\n",
      "Test Accuracy: 11.93%\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(train_generator, epochs=50, validation_data=validation_generator)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "test_loss, test_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Test Accuracy: {test_accuracy*100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ead54abe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 34s 214ms/step\n",
      "Accuracy: 0.0994\n",
      "Micro-Averaged F1 Score: 0.09940000000000002\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "\n",
    "\n",
    "# Assuming you have already loaded your test data and model\n",
    "# Make predictions using the model\n",
    "y_pred = model.predict(validation_generator)\n",
    "\n",
    "# Convert the predicted probabilities to class labels\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# Convert one-hot encoded true labels to class labels\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_true_classes, y_pred_classes)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate the micro-averaged F1 score\n",
    "micro_f1 = f1_score(y_true_classes, y_pred_classes, average='micro')\n",
    "\n",
    "print(f\"Micro-Averaged F1 Score: {micro_f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f42dd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5bed4f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33751682",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221c3887",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54455dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d18dbbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867dd26b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64cee8a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8810ea33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84680444",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd53b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3773f339",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff07bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers.legacy import Adam as LegacyAdam\n",
    "\n",
    "import cv2\n",
    "\n",
    "# Load the CIFAR-10 dataset\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize the pixel values between 0 and 1\n",
    "x_train = x_train.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "# Resize the images to (224, 224)\n",
    "x_train_resized = [cv2.resize(image, (224, 224)) for image in x_train]\n",
    "x_test_resized = [cv2.resize(image, (224, 224)) for image in x_test]\n",
    "\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "x_train_resized = np.array(x_train_resized)\n",
    "x_test_resized = np.array(x_test_resized)\n",
    "\n",
    "# Convert the labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "\n",
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = LegacyAdam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(x_train_resized, y_train, batch_size=64, epochs=50, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f587bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resize the images to (224, 224)\n",
    "x_train_resized = [cv2.resize(image, (224, 224)) for image in x_train]\n",
    "x_test_resized = [cv2.resize(image, (224, 224)) for image in x_test]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17cd0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the lists to numpy arrays\n",
    "x_train_resized = np.array(x_train_resized)\n",
    "x_test_resized = np.array(x_test_resized)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a661af51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels to one-hot encoding\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2574ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Shape of X_train:\", np.shape(x_train_resized))\n",
    "print(\"Shape of Y_train:\", np.shape(y_train))\n",
    "print(\"Shape of X_test:\", np.shape(x_test_resized))\n",
    "print(\"Shape of Y_test:\", np.shape(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758d7454",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the ResNet model without the top (fully connected) layers\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add the top layers for classification\n",
    "model = Sequential()\n",
    "model.add(base_model)\n",
    "model.add(GlobalAveragePooling2D())\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "optimizer = LegacyAdam(learning_rate=0.001)\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a9116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model.fit(x_train_resized, y_train, batch_size=64, epochs=50, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960bd789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "# Assuming you have trained a model and obtained predicted probabilities on x_test\n",
    "y_pred_prob = model.predict(x_test)\n",
    "\n",
    "# Convert predicted probabilities to predicted labels\n",
    "y_pred = np.argmax(y_pred_prob, axis=1)\n",
    "\n",
    "# Convert y_test to predicted labels format\n",
    "y_test_labels = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test_labels, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Calculate F1 score (micro-average)\n",
    "f1_micro = f1_score(y_test_labels, y_pred, average='micro')\n",
    "print(\"F1 Score (Micro):\", f1_micro)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1b34d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
